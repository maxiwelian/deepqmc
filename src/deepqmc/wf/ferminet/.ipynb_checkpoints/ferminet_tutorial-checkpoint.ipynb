{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_x = 5\n",
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "        \n",
    "        self.lin = nn.Linear(5, 5)\n",
    "        self.ones = torch.ones((n_x, n_x))\n",
    "        \n",
    "    def forward(self):\n",
    "        return self.lin(torch.ones((n_x, n_x)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training': True, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_hooks': OrderedDict(), '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict([('lin', Linear(in_features=5, out_features=5, bias=True))]), 'ones': tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])}\n",
      "torch.float32\n",
      "{'training': True, '_parameters': OrderedDict([('weight', Parameter containing:\n",
      "tensor([[ 0.2408,  0.0732, -0.0449, -0.2588, -0.2027],\n",
      "        [ 0.1210,  0.1605, -0.0500, -0.1688, -0.3994],\n",
      "        [-0.1066,  0.1030,  0.0360, -0.0468, -0.2488],\n",
      "        [-0.1699,  0.2313,  0.2506, -0.2814, -0.4082],\n",
      "        [-0.4192,  0.3023,  0.1319,  0.2258, -0.3570]], requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([-0.0204,  0.2478, -0.0723,  0.3488,  0.3833], requires_grad=True))]), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_hooks': OrderedDict(), '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict(), 'in_features': 5, 'out_features': 5}\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "m = model()\n",
    "print(vars(m))\n",
    "# m.device\n",
    "print(m.ones.dtype)\n",
    "print(vars(m.lin))\n",
    "m.to(torch.float64)\n",
    "print(m.ones.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  = torch.ones((n_x, n_x))\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
